{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting FlagEmbedding\n",
      "  Downloading FlagEmbedding-1.3.4.tar.gz (163 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from FlagEmbedding) (2.6.0)\n",
      "Requirement already satisfied: transformers>=4.44.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from FlagEmbedding) (4.48.2)\n",
      "Collecting datasets>=2.19.0 (from FlagEmbedding)\n",
      "  Downloading datasets-3.3.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting accelerate>=0.20.1 (from FlagEmbedding)\n",
      "  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: sentence_transformers in /home/ubuntu/.local/lib/python3.10/site-packages (from FlagEmbedding) (3.4.1)\n",
      "Collecting peft (from FlagEmbedding)\n",
      "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting ir-datasets (from FlagEmbedding)\n",
      "  Downloading ir_datasets-0.5.9-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting sentencepiece (from FlagEmbedding)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: protobuf in /home/ubuntu/.local/lib/python3.10/site-packages (from FlagEmbedding) (5.29.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from accelerate>=0.20.1->FlagEmbedding) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from accelerate>=0.20.1->FlagEmbedding) (24.2)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/.local/lib/python3.10/site-packages (from accelerate>=0.20.1->FlagEmbedding) (6.1.1)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from accelerate>=0.20.1->FlagEmbedding) (0.28.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from accelerate>=0.20.1->FlagEmbedding) (0.5.2)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=2.19.0->FlagEmbedding) (3.17.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.19.0->FlagEmbedding)\n",
      "  Downloading pyarrow-19.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.19.0->FlagEmbedding)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=2.19.0->FlagEmbedding) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=2.19.0->FlagEmbedding) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=2.19.0->FlagEmbedding) (4.67.1)\n",
      "Collecting xxhash (from datasets>=2.19.0->FlagEmbedding)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=2.19.0->FlagEmbedding)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.19.0->FlagEmbedding)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=2.19.0->FlagEmbedding) (3.11.11)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.6.0->FlagEmbedding) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers>=4.44.2->FlagEmbedding) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers>=4.44.2->FlagEmbedding) (0.21.0)\n",
      "Collecting beautifulsoup4>=4.4.1 (from ir-datasets->FlagEmbedding)\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting inscriptis>=2.2.0 (from ir-datasets->FlagEmbedding)\n",
      "  Downloading inscriptis-2.5.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting lxml>=4.5.2 (from ir-datasets->FlagEmbedding)\n",
      "  Downloading lxml-5.3.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting trec-car-tools>=2.5.4 (from ir-datasets->FlagEmbedding)\n",
      "  Downloading trec_car_tools-2.6-py3-none-any.whl.metadata (640 bytes)\n",
      "Collecting lz4>=3.1.10 (from ir-datasets->FlagEmbedding)\n",
      "  Downloading lz4-4.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting warc3-wet>=0.2.3 (from ir-datasets->FlagEmbedding)\n",
      "  Downloading warc3_wet-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting warc3-wet-clueweb09>=0.2.5 (from ir-datasets->FlagEmbedding)\n",
      "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting zlib-state>=0.1.3 (from ir-datasets->FlagEmbedding)\n",
      "  Downloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting ijson>=3.1.3 (from ir-datasets->FlagEmbedding)\n",
      "  Downloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting unlzw3>=0.2.1 (from ir-datasets->FlagEmbedding)\n",
      "  Downloading unlzw3-0.2.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers->FlagEmbedding) (1.6.1)\n",
      "Requirement already satisfied: scipy in /home/ubuntu/.local/lib/python3.10/site-packages (from sentence_transformers->FlagEmbedding) (1.15.1)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from sentence_transformers->FlagEmbedding) (9.0.1)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4>=4.4.1->ir-datasets->FlagEmbedding)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.0->FlagEmbedding) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.0->FlagEmbedding) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.0->FlagEmbedding) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.0->FlagEmbedding) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.0->FlagEmbedding) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.0->FlagEmbedding) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.0->FlagEmbedding) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.19.0->FlagEmbedding) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.19.0->FlagEmbedding) (2025.1.31)\n",
      "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir-datasets->FlagEmbedding)\n",
      "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch>=1.6.0->FlagEmbedding) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas->datasets>=2.19.0->FlagEmbedding) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets>=2.19.0->FlagEmbedding) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas->datasets>=2.19.0->FlagEmbedding) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers->FlagEmbedding) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers->FlagEmbedding) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.19.0->FlagEmbedding) (1.16.0)\n",
      "Downloading accelerate-1.3.0-py3-none-any.whl (336 kB)\n",
      "Downloading datasets-3.3.1-py3-none-any.whl (484 kB)\n",
      "Downloading ir_datasets-0.5.9-py3-none-any.whl (347 kB)\n",
      "Downloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:04\u001b[0mm\n",
      "\u001b[?25hDownloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Downloading ijson-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Downloading inscriptis-2.5.3-py3-none-any.whl (45 kB)\n",
      "Downloading lxml-5.3.1-cp310-cp310-manylinux_2_28_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m85.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[?25hDownloading lz4-4.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading pyarrow-19.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m109.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:02\u001b[0m00:12\u001b[0m\n",
      "\u001b[?25hDownloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
      "Downloading unlzw3-0.2.3-py3-none-any.whl (6.7 kB)\n",
      "Downloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)\n",
      "Downloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Building wheels for collected packages: FlagEmbedding, warc3-wet-clueweb09, cbor\n",
      "  Building wheel for FlagEmbedding (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for FlagEmbedding: filename=FlagEmbedding-1.3.4-py3-none-any.whl size=232544 sha256=dedc8d4e10860133f15c61ac2b08415e185be0fd32f7d5b9b92ac1ea43bd2721\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/59/8c/ba/90918a0fe0371cda2d087cffe7eb4bb4495409b6c67873a410\n",
      "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18965 sha256=56d08d4c31d31b2a61f67a641ee095cee0ed75d9fb3aaab0511d766fbf1eff28\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/1a/d7/91/7ffb991df87e62355d945745035470ba2616aa3d83a250b5f9\n",
      "  Building wheel for cbor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cbor: filename=cbor-1.0.0-py3-none-any.whl size=10072 sha256=f5a1bc2fcf6ffb3327d20781a6becac59e79e24d2ab47e0fc113658e7e3b3acb\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\n",
      "Successfully built FlagEmbedding warc3-wet-clueweb09 cbor\n",
      "Installing collected packages: warc3-wet-clueweb09, warc3-wet, sentencepiece, ijson, cbor, zlib-state, xxhash, unlzw3, trec-car-tools, soupsieve, pyarrow, lz4, lxml, fsspec, dill, multiprocess, inscriptis, beautifulsoup4, ir-datasets, accelerate, peft, datasets, FlagEmbedding\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.2.0\n",
      "    Uninstalling fsspec-2025.2.0:\n",
      "      Successfully uninstalled fsspec-2025.2.0\n",
      "Successfully installed FlagEmbedding-1.3.4 accelerate-1.3.0 beautifulsoup4-4.13.3 cbor-1.0.0 datasets-3.3.1 dill-0.3.8 fsspec-2024.12.0 ijson-3.3.0 inscriptis-2.5.3 ir-datasets-0.5.9 lxml-5.3.1 lz4-4.4.3 multiprocess-0.70.16 peft-0.14.0 pyarrow-19.0.0 sentencepiece-0.2.0 soupsieve-2.6 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 xxhash-3.5.0 zlib-state-0.1.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install FlagEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.BgeM3 at 0x7194d46fb6a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mПри выполнении кода в текущей ячейке или предыдущей ячейке ядро аварийно завершило работу. \n",
      "\u001b[1;31mПроверьте код в ячейках, чтобы определить возможную причину сбоя. \n",
      "\u001b[1;31mЩелкните <a href='https://aka.ms/vscodeJupyterKernelCrash'>здесь</a>, чтобы получить дополнительные сведения. \n",
      "\u001b[1;31mПодробнее см. в <a href='command:jupyter.viewOutput'>журнале Jupyter</a>."
     ]
    }
   ],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "from FlagEmbedding import FlagReranker\n",
    "import torch \n",
    "from typing import Dict, Optional, List, Tuple\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from sentence_transformers import CrossEncoder, SentenceTransformer\n",
    "\n",
    "\n",
    "class BgeM3:\n",
    "    def __init__(self, model_name: str = \"BAAI/bge-m3\"):\n",
    "        # Преобразуем имя модели для использования в имени сервиса\n",
    "        self.model_name = model_name\n",
    "        self.ready = False\n",
    "        self.model = None\n",
    "        self.gpu = torch.cuda.is_available()\n",
    "        self.device = \"cuda\" if self.gpu else \"cpu\"\n",
    "        self.load()\n",
    "\n",
    "    def load(self) -> None:\n",
    "        # Загружаем модель через SentenceTransformer с указанием устройства\n",
    "        self.model = SentenceTransformer(self.model_name, device=self.device)\n",
    "        self.ready = True\n",
    "\n",
    "    def predict(\n",
    "        self, request_data: Dict, request_headers: Optional[Dict] = None\n",
    "    ) -> Dict:\n",
    "        texts: List[Tuple[str, str]] = request_data[\"texts\"]\n",
    "        texts_for_model = [text for _, text in texts]\n",
    "\n",
    "        embeddings = self.model.encode(\n",
    "            texts_for_model,\n",
    "            show_progress_bar=False,\n",
    "            convert_to_tensor=False,\n",
    "            max_length=1024,\n",
    "        )\n",
    "\n",
    "        # Возвращаем эмбеддинги в формате списка\n",
    "        return {\"embeddings\": embeddings}\n",
    "\n",
    "BgeM3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.predict(\n",
    "    request_data={\n",
    "        \"texts\": [\n",
    "            (\"query\", \"how much protein should a female eat\"),\n",
    "            (\"query\", \"南瓜的家常做法\"),\n",
    "            (\n",
    "                \"passage\",\n",
    "                \"As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
    "            ),\n",
    "            (\n",
    "                \"passage\",\n",
    "                \"1.清炒南瓜丝 原料:嫩南瓜半个 调料:葱、盐、白糖、鸡精 做法: 1、南瓜用刀薄薄的削去表面一层皮,用勺子刮去瓤 2、擦成细丝(没有擦菜板就用刀慢慢切成细丝) 3、锅烧热放油,入葱花煸出香味 4、入南瓜丝快速翻炒一分钟左右,放盐、一点白糖和鸡精调味出锅 2.香葱炒南瓜 原料:南瓜1只 调料:香葱、蒜末、橄榄油、盐 做法: 1、将南瓜去皮,切成片 2、油锅8成热后,将蒜末放入爆香 3、爆香后,将南瓜片放入,翻炒 4、在翻炒的同时,可以不时地往锅里加水,但不要太多 5、放入盐,炒匀 6、南瓜差不多软和绵了之后,就可以关火 7、撒入香葱,即可出锅\",\n",
    "            ),\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response[\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_data = {\n",
    "    \"texts\": [\n",
    "        (\"query\", \"how much protein should a female eat\"),\n",
    "        (\"query\", \"南瓜的家常做法\"),\n",
    "        (\n",
    "            \"passage\",\n",
    "            \"As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
    "        ),\n",
    "        (\n",
    "            \"passage\",\n",
    "            \"1.清炒南瓜丝 原料:嫩南瓜半个 调料:葱、盐、白糖、鸡精 做法: 1、南瓜用刀薄薄的削去表面一层皮,用勺子刮去瓤 2、擦成细丝(没有擦菜板就用刀慢慢切成细丝) 3、锅烧热放油,入葱花煸出香味 4、入南瓜丝快速翻炒一分钟左右,放盐、一点白糖和鸡精调味出锅 2.香葱炒南瓜 原料:南瓜1只 调料:香葱、蒜末、橄榄油、盐 做法: 1、将南瓜去皮,切成片 2、油锅8成热后,将蒜末放入爆香 3、爆香后,将南瓜片放入,翻炒 4、在翻炒的同时,可以不时地往锅里加水,但不要太多 5、放入盐,炒匀 6、南瓜差不多软和绵了之后,就可以关火 7、撒入香葱,即可出锅\",\n",
    "        ),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.post(\n",
    "    \"http://localhost:8100/v1/models/BAAI_bge_reranker_v2_m3:predict\",\n",
    "    json=request_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"scores\":[-7.6122660636901855,-8.917508125305176,-10.979835510253906,-7.614435195922852]}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02018592692911625, 0.011204439215362072, -0.04514234513044357, -0.0394994355738163, 0.017567913979291916, -0.025198882445693016, -0.025208625942468643, 0.06422241777181625, 0.03213871642947197, -0.026800913736224174]\n",
      "[0.04857625067234039, 0.0593828447163105, 0.003986190538853407, -0.020708534866571426, 0.024149436503648758, -0.014857766218483448, -0.0005905894795432687, 0.05966014415025711, 0.019906768575310707, -0.013999292626976967]\n",
      "[0.03266947343945503, 0.004132492933422327, -0.05025511234998703, -0.021615885198116302, 0.03252109885215759, -0.04739893600344658, -0.03377801179885864, 0.04409226030111313, 0.04651404544711113, -0.051693595945835114]\n",
      "[0.04768911749124527, 0.05657833069562912, 0.009223462082445621, -0.018913310021162033, 0.01720563881099224, -0.011063066311180592, 0.014807222411036491, 0.05328642204403877, 0.0010438720928505063, -0.012906507588922977]\n"
     ]
    }
   ],
   "source": [
    "for embed in response.json()[\"embeddings\"]:\n",
    "    print(embed[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mvdremin/miniforge3/envs/gigachain/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import sentence_transformers\n",
    "\n",
    "model = sentence_transformers.SentenceTransformer(\n",
    "    \"intfloat/multilingual-e5-large-instruct\",\n",
    "    prompts={\n",
    "        \"query\": \"Instruct: Given a web search query, retrieve relevant passages that answer the query\\nQuery: \"\n",
    "    },\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.020185990259051323, 0.011204462498426437, -0.04514240100979805, -0.03949938341975212, 0.01756785623729229, -0.02519889548420906, -0.025208545848727226, 0.06422246247529984, 0.03213874623179436, -0.026800911873579025]\n",
      "[0.048576340079307556, 0.05938291922211647, 0.003986139316111803, -0.020708562806248665, 0.02414940483868122, -0.014857753179967403, -0.0005905400612391531, 0.05966009199619293, 0.019906774163246155, -0.013999267481267452]\n",
      "[0.02288028784096241, 0.00972859188914299, -0.04084709659218788, -0.027168048545718193, 0.03248666226863861, -0.044196922332048416, -0.028844982385635376, 0.0638773962855339, 0.04096970334649086, -0.04006381332874298]\n",
      "[0.04198748245835304, 0.0473160557448864, 0.004951199982315302, -0.026837505400180817, 0.029732720926404, -0.012284206226468086, 0.01857127994298935, 0.055720094591379166, 0.012999649159610271, -0.0016542201628908515]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(\n",
    "    [text[1] for text in request_data[\"texts\"]],\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True,\n",
    "    prompt_name=\"query\",\n",
    ")\n",
    "for embed in embeddings.tolist():\n",
    "    print(embed[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.020185990259051323, 0.011204462498426437, -0.04514240100979805, -0.03949938341975212, 0.01756785623729229, -0.02519889548420906, -0.025208545848727226, 0.06422246247529984, 0.03213874623179436, -0.026800911873579025]\n",
      "[0.048576340079307556, 0.05938291922211647, 0.003986139316111803, -0.020708562806248665, 0.02414940483868122, -0.014857753179967403, -0.0005905400612391531, 0.05966009199619293, 0.019906774163246155, -0.013999267481267452]\n",
      "[0.02288028784096241, 0.00972859188914299, -0.04084709659218788, -0.027168048545718193, 0.03248666226863861, -0.044196922332048416, -0.028844982385635376, 0.0638773962855339, 0.04096970334649086, -0.04006381332874298]\n",
      "[0.04198748245835304, 0.0473160557448864, 0.004951199982315302, -0.026837505400180817, 0.029732720926404, -0.012284206226468086, 0.01857127994298935, 0.055720094591379166, 0.012999649159610271, -0.0016542201628908515]\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.embed_documents(\n",
    "    [text[1] for text in request_data[\"texts\"]],\n",
    ")\n",
    "for embed in embeddings:\n",
    "    print(embed[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/multilingual-e5-large-instruct\",\n",
    "    model_kwargs={\n",
    "        \"prompts\": {\n",
    "            \"query\": \"Instruct: Given a web search query, retrieve relevant passages that answer the query\\nQuery: \"\n",
    "        },\n",
    "        \"device\": \"cpu\",\n",
    "    },\n",
    "    encode_kwargs={\"normalize_embeddings\": True, \"prompt_name\": \"query\"},\n",
    ")\n",
    "\n",
    "embeddings = model.embed_documents(\n",
    "    [text[1] for text in request_data[\"texts\"]],\n",
    ")\n",
    "for embed in embeddings:\n",
    "    print(embed[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02380332164466381, 0.0233569648116827, -0.04431702941656113, -0.03123355843126774, 0.010486085899174213, -0.02713814191520214, -0.020534325391054153, 0.04382570832967758, 0.020839078351855278, -0.02268272452056408]\n",
      "[0.05234979838132858, 0.06129227578639984, 0.004823273979127407, -0.02078615128993988, 0.02621222846210003, -0.011689964681863785, 0.0046771918423473835, 0.05655382201075554, 0.020846951752901077, -0.02351178228855133]\n",
      "[0.03266941010951996, 0.004132444504648447, -0.050254981964826584, -0.021615881472826004, 0.03252111002802849, -0.047398969531059265, -0.03377801552414894, 0.04409223794937134, 0.04651397466659546, -0.051693618297576904]\n",
      "[0.04768915846943855, 0.05657828971743584, 0.009223384782671928, -0.018913382664322853, 0.017205655574798584, -0.011062991805374622, 0.014807027764618397, 0.053286388516426086, 0.0010437833843752742, -0.012906370684504509]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(\n",
    "    [text[1] for text in request_data[\"texts\"]], show_progress_bar=True\n",
    ")\n",
    "for embed in embeddings.tolist():\n",
    "    print(embed[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EMBEDDER_MODEL_NAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_milvus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Milvus\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_huggingface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[0;32m----> 5\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings(model_name\u001b[38;5;241m=\u001b[39m\u001b[43mEMBEDDER_MODEL_NAME\u001b[49m)\n\u001b[1;32m      7\u001b[0m Milvus(\n\u001b[1;32m      8\u001b[0m     embedding_function\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[1;32m      9\u001b[0m     connection_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muri\u001b[39m\u001b[38;5;124m\"\u001b[39m: path},\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EMBEDDER_MODEL_NAME' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDER_MODEL_NAME)\n",
    "\n",
    "Milvus(\n",
    "    embedding_function=embeddings,\n",
    "    connection_args={\"uri\": path},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import ElasticSearchBM25Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElasticSearchBM25Retriever()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
